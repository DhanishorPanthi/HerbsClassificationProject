{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications.densenet import DenseNet121\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def walk_through_dir(dir_path):\n",
    "  \"\"\"Walks through the directory and returns it's content\"\"\"\n",
    "  for dir_path, dirname, filenames in os.walk(dir_path):\n",
    "    print(f\"There are {len(dirname)} directories and {len(filenames)} images in {dir_path}\")\n",
    "\n",
    "walk_through_dir(\"D:\\\\Ashutosh\\\\Herbs\\\\Cleanede_Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATH = \"D:\\\\Ashutosh\\\\Herbs\\\\Cleanede_Data\"\n",
    "\n",
    "# Get all image paths\n",
    "image_path_list = list(Path(IMAGE_PATH).glob(\"**/*/*\"))\n",
    "rand_image = random.choice(image_path_list)\n",
    "image_class = rand_image.parent.stem\n",
    "\n",
    "# Open and display a random image\n",
    "img = Image.open(rand_image)\n",
    "print(f\"The image path is {rand_image} and the width and height are {img.width} {img.height}\")\n",
    "img.show()  # Uncomment if you want to display the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_random_augmentation(image):\n",
    "    \"\"\"Apply random augmentations to an image\"\"\"\n",
    "    image = tf.convert_to_tensor(np.array(image), dtype=tf.float32)\n",
    "    if tf.reduce_max(image) > 1.0:\n",
    "        image = image / 255.0\n",
    "    \n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    image = tf.image.random_brightness(image, max_delta=0.2)\n",
    "    image = tf.image.random_contrast(image, lower=0.8, upper=1.2)\n",
    "    image = tf.image.random_hue(image, max_delta=0.1)\n",
    "    image = tf.image.random_saturation(image, lower=0.8, upper=1.2)\n",
    "    \n",
    "    image = tf.clip_by_value(image, 0.0, 1.0)\n",
    "    image = (image * 255).astype(np.uint8)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_transformed_image(img_paths, transform, n=3, seed=42):\n",
    "    \"\"\"Plot original and transformed images\"\"\"\n",
    "    random.seed(seed)\n",
    "    random_image_paths = random.sample(img_paths, k=n)\n",
    "    \n",
    "    for image_path in random_image_paths:\n",
    "        with Image.open(image_path) as f:\n",
    "            fig, ax = plt.subplots(figsize=(12, 5), nrows=1, ncols=2)\n",
    "            ax[0].imshow(f)\n",
    "            ax[0].set_title(f\"Original image with {f.size}\")\n",
    "            ax[0].axis('off')\n",
    "            \n",
    "            transformed_image = transform(f)\n",
    "            ax[1].imshow(transformed_image)\n",
    "            ax[1].set_title(\"Transformed image\")\n",
    "            ax[1].axis('off')\n",
    "            \n",
    "            fig.suptitle(f\"Class: {image_path.parent.stem}\")\n",
    "            plt.show()\n",
    "\n",
    "# Plot some example augmentations\n",
    "plot_transformed_image(img_paths=image_path_list, transform=apply_random_augmentation, n=3, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folder(fd):\n",
    "    if not os.path.exists(fd):\n",
    "        os.makedirs(fd)\n",
    "\n",
    "output = 'D:\\\\Ashutosh\\\\Herbs\\\\Output\\\\ModelName'  \n",
    "create_folder(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only rescaling for validation\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set image size and batch size\n",
    "image_size = (224, 224)\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_directory = 'D:\\\\Ashutosh\\\\Herbs\\\\Cleanede_Data\\\\Train'\n",
    "validation_directory = 'D:\\\\Ashutosh\\\\Herbs\\\\Cleanede_Data\\\\Val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_directory,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_directory,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DenseNet121 model\n",
    "base_model = DenseNet121(\n",
    "    include_top=False,\n",
    "    input_shape=(image_size[0], image_size[1], 3),\n",
    "    weights='imagenet'\n",
    ")\n",
    "\n",
    "model_dense = keras.models.Sequential([\n",
    "    base_model,\n",
    "    keras.layers.GlobalAveragePooling2D(),\n",
    "    keras.layers.Dense(512, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(109, activation='softmax')  # Verify this matches your number of classes\n",
    "])\n",
    "\n",
    "model_dense.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks\n",
    "filepath = os.path.join(output, \"HerbClassification_BEST.h5\")\n",
    "csv_logger = CSVLogger(os.path.join(output, f\"CSV_Logger-MC_ML-{time.time()}.csv\"))\n",
    "early_stop = EarlyStopping(patience=15, monitor='val_loss', verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=0.0001, verbose=1)\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath,\n",
    "    monitor='val_accuracy',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    mode='max'\n",
    ")\n",
    "\n",
    "callbacks_list = [checkpoint, reduce_lr, early_stop, csv_logger]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model_dense.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss=CategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Calculate steps per epoch\n",
    "steps_per_epoch = train_generator.samples // batch_size\n",
    "validation_steps = validation_generator.samples // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "epochs = 200\n",
    "densenet_history = model_dense.fit(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=callbacks_list,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_steps=validation_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final weights\n",
    "model_dense.save_weights(os.path.join(output, 'herbs_100Epoch_Last_WT.h5'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
